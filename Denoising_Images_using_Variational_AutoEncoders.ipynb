{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "453a9f00-67c7-4d4a-abe8-cd2d83654f0a",
      "metadata": {
        "id": "453a9f00-67c7-4d4a-abe8-cd2d83654f0a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4575a81d-8dbf-4261-a7ad-24b0958f4642",
      "metadata": {
        "id": "4575a81d-8dbf-4261-a7ad-24b0958f4642"
      },
      "outputs": [],
      "source": [
        "img_size = 784\n",
        "hidden_dim = 400\n",
        "latent_dim = 20\n",
        "batch_size = 128\n",
        "epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b6ee3d65-eee4-49a4-a919-d40ff2a68df5",
      "metadata": {
        "id": "b6ee3d65-eee4-49a4-a919-d40ff2a68df5"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "18d3d884-a1e6-4ea3-8140-5ce62844ca66",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18d3d884-a1e6-4ea3-8140-5ce62844ca66",
        "outputId": "f7c2443a-917b-453c-9b39-05b219ced362"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 100108621.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 105243869.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 30092250.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 988200.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_dataset = torchvision.datasets.MNIST(root=\"./data\",\n",
        "                                                  train = True,\n",
        "                                                  transform = transforms.ToTensor(),\n",
        "                                                  download=True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle = True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root=\"./data\",\n",
        "                                                  train = False,\n",
        "                                                  transform = transforms.ToTensor(),\n",
        "                                                  download=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle = False)\n",
        "\n",
        "# save img to dir\n",
        "sample_dir = \"output\"\n",
        "\n",
        "if not os.path.exists(sample_dir):\n",
        "    os.makedirs(sample_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "128e4472-0235-45a7-9be3-9ce23a6e713b",
      "metadata": {
        "id": "128e4472-0235-45a7-9be3-9ce23a6e713b"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VAE,self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(img_size,hidden_dim)\n",
        "        self.fc2_mean = nn.Linear(hidden_dim,latent_dim)\n",
        "        self.fc2_logvar = nn.Linear(hidden_dim,latent_dim)\n",
        "        self.fc3 = nn.Linear(latent_dim, hidden_dim)\n",
        "        self.fc4 = nn.Linear(hidden_dim, img_size)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = F.relu(self.fc1(x))\n",
        "        mu = self.fc2_mean(h)\n",
        "        logvar = self.fc2_logvar(h)\n",
        "\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu,logvar):\n",
        "        std = torch.exp(logvar/2)\n",
        "        eps = torch.randn_like(std)\n",
        "\n",
        "        return mu + eps*std\n",
        "\n",
        "    def decode(self,z):\n",
        "        h = F.relu(self.fc3(z))\n",
        "        out = torch.sigmoid(self.fc4(h))\n",
        "\n",
        "        return out\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu,logvar = self.encode(x.view(-1,img_size))\n",
        "        z = self.reparameterize(mu,logvar)\n",
        "        out = self.decode(z)\n",
        "\n",
        "        return out,mu,logvar\n",
        "\n",
        "\n",
        "model = VAE().to(device)\n",
        "optim = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "40fe39ad-0064-4dd6-b6c2-f41ff87c2eda",
      "metadata": {
        "id": "40fe39ad-0064-4dd6-b6c2-f41ff87c2eda"
      },
      "outputs": [],
      "source": [
        "def loss_fn(out,img,mu,logvar):\n",
        "    bce = F.binary_cross_entropy(out,img.view(-1,img_size), reduction=\"sum\")\n",
        "    kld = 0.5*torch.sum(logvar.exp() + mu**2 - 1 - logvar)\n",
        "\n",
        "    return bce+kld\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for i,(images,_) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        out,mu,logvar = model(images)\n",
        "        loss = loss_fn(out,images,mu,logvar)\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "        if i%100==0:\n",
        "            print(\"Train Epoch {} [Batch {}/{}]\\tLoss: {:.3f}\".format(epoch, i, len(train_loader), loss.item()/len(images)))\n",
        "\n",
        "    print(f\"Epoch {epoch}, Average Loss: {(train_loss/len(train_loader.dataset)):.3f}\")\n",
        "\n",
        "def test(epoch):\n",
        "    model.eval()\n",
        "\n",
        "    test_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx,(images,_) in enumerate(test_loader):\n",
        "            images = images.to(device)\n",
        "            out,mu,logvar = model(images)\n",
        "            test_loss += loss_fn(out,images,mu,logvar).item()\n",
        "\n",
        "            if batch_idx == 0:\n",
        "                comparison = torch.cat([images[:5], out.view(batch_size,1,28,28)[:5]])\n",
        "                save_image(comparison.cpu(), 'output/out_' + str(epoch) + '.png',nrow=5)\n",
        "\n",
        "        print(f\">> Average Loss: {test_loss/len(test_loader.dataset):.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4aef227b-89d0-4666-977c-170334d37941",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aef227b-89d0-4666-977c-170334d37941",
        "outputId": "f7c32e01-93e5-413e-8867-2539f98c955d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch 1 [Batch 0/469]\tLoss: 549.777\n",
            "Train Epoch 1 [Batch 100/469]\tLoss: 183.312\n",
            "Train Epoch 1 [Batch 200/469]\tLoss: 154.053\n",
            "Train Epoch 1 [Batch 300/469]\tLoss: 139.956\n",
            "Train Epoch 1 [Batch 400/469]\tLoss: 130.133\n",
            "Epoch 1, Average Loss: 164.566\n",
            ">> Average Loss: 127.882\n",
            "Train Epoch 2 [Batch 0/469]\tLoss: 129.915\n",
            "Train Epoch 2 [Batch 100/469]\tLoss: 123.803\n",
            "Train Epoch 2 [Batch 200/469]\tLoss: 128.375\n",
            "Train Epoch 2 [Batch 300/469]\tLoss: 118.118\n",
            "Train Epoch 2 [Batch 400/469]\tLoss: 115.804\n",
            "Epoch 2, Average Loss: 121.966\n",
            ">> Average Loss: 116.304\n",
            "Train Epoch 3 [Batch 0/469]\tLoss: 119.898\n",
            "Train Epoch 3 [Batch 100/469]\tLoss: 118.642\n",
            "Train Epoch 3 [Batch 200/469]\tLoss: 112.803\n",
            "Train Epoch 3 [Batch 300/469]\tLoss: 118.791\n",
            "Train Epoch 3 [Batch 400/469]\tLoss: 109.729\n",
            "Epoch 3, Average Loss: 114.898\n",
            ">> Average Loss: 112.291\n",
            "Train Epoch 4 [Batch 0/469]\tLoss: 110.326\n",
            "Train Epoch 4 [Batch 100/469]\tLoss: 115.354\n",
            "Train Epoch 4 [Batch 200/469]\tLoss: 115.141\n",
            "Train Epoch 4 [Batch 300/469]\tLoss: 109.236\n",
            "Train Epoch 4 [Batch 400/469]\tLoss: 113.216\n",
            "Epoch 4, Average Loss: 111.842\n",
            ">> Average Loss: 110.031\n",
            "Train Epoch 5 [Batch 0/469]\tLoss: 111.068\n",
            "Train Epoch 5 [Batch 100/469]\tLoss: 110.734\n",
            "Train Epoch 5 [Batch 200/469]\tLoss: 111.106\n",
            "Train Epoch 5 [Batch 300/469]\tLoss: 110.635\n",
            "Train Epoch 5 [Batch 400/469]\tLoss: 106.631\n",
            "Epoch 5, Average Loss: 110.089\n",
            ">> Average Loss: 108.743\n",
            "Train Epoch 6 [Batch 0/469]\tLoss: 110.132\n",
            "Train Epoch 6 [Batch 100/469]\tLoss: 107.837\n",
            "Train Epoch 6 [Batch 200/469]\tLoss: 106.959\n",
            "Train Epoch 6 [Batch 300/469]\tLoss: 112.186\n",
            "Train Epoch 6 [Batch 400/469]\tLoss: 107.383\n",
            "Epoch 6, Average Loss: 108.861\n",
            ">> Average Loss: 107.863\n",
            "Train Epoch 7 [Batch 0/469]\tLoss: 110.660\n",
            "Train Epoch 7 [Batch 100/469]\tLoss: 107.740\n",
            "Train Epoch 7 [Batch 200/469]\tLoss: 107.391\n",
            "Train Epoch 7 [Batch 300/469]\tLoss: 104.496\n",
            "Train Epoch 7 [Batch 400/469]\tLoss: 106.979\n",
            "Epoch 7, Average Loss: 108.018\n",
            ">> Average Loss: 107.235\n",
            "Train Epoch 8 [Batch 0/469]\tLoss: 106.766\n",
            "Train Epoch 8 [Batch 100/469]\tLoss: 108.973\n",
            "Train Epoch 8 [Batch 200/469]\tLoss: 108.329\n",
            "Train Epoch 8 [Batch 300/469]\tLoss: 102.975\n",
            "Train Epoch 8 [Batch 400/469]\tLoss: 107.612\n",
            "Epoch 8, Average Loss: 107.371\n",
            ">> Average Loss: 106.622\n",
            "Train Epoch 9 [Batch 0/469]\tLoss: 108.218\n",
            "Train Epoch 9 [Batch 100/469]\tLoss: 104.948\n",
            "Train Epoch 9 [Batch 200/469]\tLoss: 106.659\n",
            "Train Epoch 9 [Batch 300/469]\tLoss: 103.559\n",
            "Train Epoch 9 [Batch 400/469]\tLoss: 110.718\n",
            "Epoch 9, Average Loss: 106.797\n",
            ">> Average Loss: 106.071\n",
            "Train Epoch 10 [Batch 0/469]\tLoss: 106.926\n",
            "Train Epoch 10 [Batch 100/469]\tLoss: 110.790\n",
            "Train Epoch 10 [Batch 200/469]\tLoss: 104.602\n",
            "Train Epoch 10 [Batch 300/469]\tLoss: 110.826\n",
            "Train Epoch 10 [Batch 400/469]\tLoss: 108.248\n",
            "Epoch 10, Average Loss: 106.399\n",
            ">> Average Loss: 105.612\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, epochs+1):\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        sample = torch.randn(64,20).to(device)\n",
        "        generated = model.decode(sample).cpu()\n",
        "        save_image(generated.view(64,1,28,28), 'output/sample_' + str(epoch)+'.png')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}